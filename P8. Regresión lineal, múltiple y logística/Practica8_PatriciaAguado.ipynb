{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÁCTICA 8: REGRESIÓN LINEAL, MÚLTIPLE Y LOGÍSTICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Técnicas de Aprendizaje Automático 2019/2020 <br>Patricia Aguado Labrador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, zipfile, urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score as ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargamos el conjunto de datos en formato zip si este no se había descargado con anterioridad en el directorio en el que se ejecuta el fichero 'ipynb' y lo descomprimimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "# El fichero zip ya existe, tomamos su dirección\n",
    "if (os.path.exists(path+'/avila.zip')):\n",
    "    dataset = path+'/avila.zip'\n",
    "# El fichero zip no existe, lo descargamos del repositorio de uci y tomamos su dirección\n",
    "else:\n",
    "    url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00459/avila.zip'\n",
    "    dataset = urllib.request.urlretrieve(url, path+'/avila.zip')\n",
    "    dataset = path+'/avila.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avila/', 'avila/avila-tr.txt', 'avila/avila-ts.txt', 'avila/avila-description.txt']\n"
     ]
    }
   ],
   "source": [
    "# Tomamos el fichero zip y extraemos su contenido \n",
    "file_zip = zipfile.ZipFile(dataset, 'r')\n",
    "try:\n",
    "    files = file_zip.namelist()\n",
    "    file_zip.extractall(path = path+'/')\n",
    "except:\n",
    "    pass\n",
    "file_zip.close()\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez descargados y descomprimidos los conjuntos de datos, los juntamos con el método concatenar de la biblioteca pandas y descargamos los datos en formato 'csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10430, 11)\n",
      "(10437, 11)\n"
     ]
    }
   ],
   "source": [
    "file_train = pd.read_csv(files[1], header= None)\n",
    "print(file_train.shape)\n",
    "\n",
    "file_test = pd.read_csv(files[2], header= None)\n",
    "print(file_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([file_train,file_test])\n",
    "# Añadimos una cabecera para nombrar los atributos\n",
    "data.columns = ['F1','F2','F3','F4','F5','F6','F7','F8','F9','F10','Class']\n",
    "# Descargamos el conjunto de datos completo en formato 'csv'\n",
    "data.to_csv(path+'/avila.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Descripción del conjunto de datos</b><br>\n",
    "El dataset Avila está formado por datos de 800 imágenes sacadas de una copia latina de la Biblia del siglo XII, la Biblia de Ávila. El conjunto de datos está compuesto por 20867 intancias y 10 atributos (tipo numérico) que representan características de las imágenes como los márgenes, el peso o la separación intercolumnar. El atributo de clase (tipo nominal) de este conjunto de datos corresponde al patrón de 12 copistas diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.165620</td>\n",
       "      <td>0.320980</td>\n",
       "      <td>0.483299</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.273364</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>0.929823</td>\n",
       "      <td>0.251173</td>\n",
       "      <td>0.159345</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.130292</td>\n",
       "      <td>0.870736</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>0.062493</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>1.436060</td>\n",
       "      <td>1.465940</td>\n",
       "      <td>0.636203</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>0.515587</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.116585</td>\n",
       "      <td>0.069915</td>\n",
       "      <td>0.068476</td>\n",
       "      <td>-0.783147</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.439463</td>\n",
       "      <td>-0.081827</td>\n",
       "      <td>-0.888236</td>\n",
       "      <td>-0.123005</td>\n",
       "      <td>0.582939</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.031541</td>\n",
       "      <td>0.297600</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>-0.583590</td>\n",
       "      <td>-0.721442</td>\n",
       "      <td>-0.307984</td>\n",
       "      <td>0.710932</td>\n",
       "      <td>1.051693</td>\n",
       "      <td>0.594169</td>\n",
       "      <td>-0.533994</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.229043</td>\n",
       "      <td>0.807926</td>\n",
       "      <td>-0.052442</td>\n",
       "      <td>0.082634</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.148790</td>\n",
       "      <td>0.635431</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>0.032902</td>\n",
       "      <td>-0.086652</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20862</td>\n",
       "      <td>-0.128929</td>\n",
       "      <td>-0.040001</td>\n",
       "      <td>0.057807</td>\n",
       "      <td>0.557894</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.930856</td>\n",
       "      <td>-0.044076</td>\n",
       "      <td>1.158458</td>\n",
       "      <td>2.277968</td>\n",
       "      <td>-0.699884</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20863</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>0.556689</td>\n",
       "      <td>-0.020434</td>\n",
       "      <td>0.176624</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.515608</td>\n",
       "      <td>0.597681</td>\n",
       "      <td>0.178349</td>\n",
       "      <td>0.625350</td>\n",
       "      <td>-0.657245</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20864</td>\n",
       "      <td>-0.054866</td>\n",
       "      <td>0.580242</td>\n",
       "      <td>0.032912</td>\n",
       "      <td>-0.016668</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>1.519109</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>-0.985508</td>\n",
       "      <td>-0.403638</td>\n",
       "      <td>1.276301</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20865</td>\n",
       "      <td>0.080916</td>\n",
       "      <td>0.588093</td>\n",
       "      <td>0.015130</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.930856</td>\n",
       "      <td>-0.270579</td>\n",
       "      <td>0.163807</td>\n",
       "      <td>-0.091823</td>\n",
       "      <td>-0.593329</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20866</td>\n",
       "      <td>0.377169</td>\n",
       "      <td>0.014957</td>\n",
       "      <td>0.381439</td>\n",
       "      <td>0.292753</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-1.470679</td>\n",
       "      <td>-0.006326</td>\n",
       "      <td>-0.494919</td>\n",
       "      <td>-0.247731</td>\n",
       "      <td>-1.212974</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20867 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             F1        F2        F3        F4        F5        F6        F7  \\\n",
       "0      0.266074 -0.165620  0.320980  0.483299  0.172340  0.273364  0.371178   \n",
       "1      0.130292  0.870736 -3.210528  0.062493  0.261718  1.436060  1.465940   \n",
       "2     -0.116585  0.069915  0.068476 -0.783147  0.261718  0.439463 -0.081827   \n",
       "3      0.031541  0.297600 -3.210528 -0.583590 -0.721442 -0.307984  0.710932   \n",
       "4      0.229043  0.807926 -0.052442  0.082634  0.261718  0.148790  0.635431   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "20862 -0.128929 -0.040001  0.057807  0.557894  0.261718 -0.930856 -0.044076   \n",
       "20863  0.266074  0.556689 -0.020434  0.176624  0.261718 -0.515608  0.597681   \n",
       "20864 -0.054866  0.580242  0.032912 -0.016668  0.261718  1.519109  0.371178   \n",
       "20865  0.080916  0.588093  0.015130  0.002250  0.261718 -0.930856 -0.270579   \n",
       "20866  0.377169  0.014957  0.381439  0.292753  0.261718 -1.470679 -0.006326   \n",
       "\n",
       "             F8        F9       F10 Class  \n",
       "0      0.929823  0.251173  0.159345     A  \n",
       "1      0.636203  0.282354  0.515587     A  \n",
       "2     -0.888236 -0.123005  0.582939     A  \n",
       "3      1.051693  0.594169 -0.533994     A  \n",
       "4      0.051062  0.032902 -0.086652     F  \n",
       "...         ...       ...       ...   ...  \n",
       "20862  1.158458  2.277968 -0.699884     X  \n",
       "20863  0.178349  0.625350 -0.657245     G  \n",
       "20864 -0.985508 -0.403638  1.276301     A  \n",
       "20865  0.163807 -0.091823 -0.593329     F  \n",
       "20866 -0.494919 -0.247731 -1.212974     H  \n",
       "\n",
       "[20867 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = pd.read_csv('avila.csv')\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(file)\n",
    "X = data[:,:10]\n",
    "# Normalizar\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLM con método de resorte o Hold-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array que tiene por columnas las 12 clases y por filas las 20867 instancias.\n",
    "# Las componentes de cada fila son todas 0, salvo la de la clase a la que pertenece la instancia donde se encuentra un 1\n",
    "d = LabelBinarizer().fit(np.unique(y)).transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separación estratificada del conjunto de datos en 2/3 y 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, d_train, d_test = train_test_split(X, d, test_size=1./3., random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTasa de acierto:\u001b[0m 0.4799\n"
     ]
    }
   ],
   "source": [
    "# Array con la tasa de precision de cada clasificador\n",
    "y_predicts = np.zeros(d_test.shape, dtype=float)\n",
    "\n",
    "# RLM, creamos un clasificador para cada clase existente y lo entrenamos con la columna correspondiente\n",
    "for i in range(d.shape[1]):\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(X_train, d_train[:,i])\n",
    "    y_predicts[:,i] = clf.predict(X_test)\n",
    "    \n",
    "# Tomamos el clasificador predicho con mayor tasa de acierto para asignarle esa clase\n",
    "class_predict = np.argmax(y_predicts, axis=1)\n",
    "class_true = np.argmax(d_test, axis=1)\n",
    "\n",
    "# Tasa de acierto\n",
    "acu = ac(class_true, class_predict)\n",
    "print(\"\\033[1mTasa de acierto:\\033[0m %.4f\" %acu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMatriz de confusión:\u001b[0m\n",
      "\n",
      "     A    B    C    D    E    F    G    H    I    W    X    Y  \n",
      "\n",
      "[[2792    0    0    0    6   32    0    0   27    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    3    0    0    0]\n",
      " [  56    0    0    0    4    3    0    0    6    0    0    0]\n",
      " [ 224    0    0    0    1    1    0    0    9    0    0    0]\n",
      " [ 675    0    0    0   18   21    0    0   15    0    1    0]\n",
      " [1285    0    0    0    0    7    0    0   16    0    0    0]\n",
      " [ 290    0    0    0    1    3    0    0    4    0    0    0]\n",
      " [ 286    0    0    0    2   29    0    0   29    0    0    0]\n",
      " [  66    0    0    0    4    4    0    0  475    0    5    0]\n",
      " [  27    0    0    0    3    0    0    0    0    0    0    0]\n",
      " [ 208    0    0    0   13    0    0    0   81    0   46    0]\n",
      " [  42    0    0    0    1    1    0    0  134    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusión\n",
    "cm = confusion_matrix(class_true, class_predict)\n",
    "\n",
    "print(\"\\033[1mMatriz de confusión:\\033[0m\\n\")\n",
    "for i in np.unique(y):\n",
    "    if (i == 'A'):\n",
    "        print(\"  \",end=\" \")\n",
    "    print(\" \",i,\"\",end=\" \")\n",
    "print(\"\\n\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLM con método de validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array que tiene por columnas las 12 clases y por filas las 20867 instancias.\n",
    "# Las componentes de cada fila son todas 0, salvo la de la clase a la que pertenece la instancia donde se encuentra un 1\n",
    "d = LabelBinarizer().fit(np.unique(y)).transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTasa de acierto:\u001b[0m 0.4818\n"
     ]
    }
   ],
   "source": [
    "# Creación de 10 particiones para realizar validación cruzada\n",
    "skf = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n",
    "# Array que almacenará la tasa de acierto de cada partición\n",
    "scores = np.zeros((10), dtype=float)\n",
    "index_score = 0\n",
    "\n",
    "# Creación, entrenamiento y predicción de los 12 clasificadores en las 10 particiones train-test\n",
    "for train_index, test_index in skf.split(X,d[:,0]):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    d_train, d_test = d[train_index], d[test_index]\n",
    "    y_predicts = np.zeros(d_test.shape, dtype=float)\n",
    "    \n",
    "    for i in range(d.shape[1]):\n",
    "        clf = LinearRegression()\n",
    "        clf.fit(X_train,d_train[:,i])\n",
    "        \n",
    "        y_predicts[:,i] = clf.predict(X_test)\n",
    "        \n",
    "    # Tomamos el clasificador predicho con mayor tasa de acierto para asignarle esa clase\n",
    "    class_predict = np.argmax(y_predicts, axis=1)\n",
    "    class_true = np.argmax(d_test, axis=1)\n",
    "    \n",
    "    # Tasa de acierto de una partición\n",
    "    scores[index_score] = ac(class_true, class_predict)\n",
    "    index_score += 1\n",
    "\n",
    "# Tasa de acierto\n",
    "print(\"\\033[1mTasa de acierto:\\033[0m %.4f\" %np.mean(scores, dtype=np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las tasas de acierto para RLM y el conjunto de datos Avila son bastante malas ya que los porcentajes de acierto no llegan ni al 50%. Vemos que a la hora de realizar validación cruzada con este método de regresión, el porcentaje de acierto solo mejora en un 0.19%, prácticamente la mejora es nula.<br>\n",
    "Podemos ver en la matriz de confusión que las clases con las que más acierta este clasificador son la A y la I, pero esto podría deberse a que estas clases no presentan características muy significativas frente a las demás clases, ya que son las que mayor frecuencia de aparición tienen a la hora de predecir otras clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística con método de resorte o Hold-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTasa de acierto:\u001b[0m 0.4931\n"
     ]
    }
   ],
   "source": [
    "# Separación 2/3 y 1/3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1./3., random_state=0, stratify=y)\n",
    "\n",
    "# Creación y entrenamiento del clasificador de Regresión Logística\n",
    "clf = LogisticRegression(random_state=0, multi_class='auto', solver='lbfgs', max_iter=500)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Tasa de acierto para los datos de prueba y las clases a las que pertenecen\n",
    "acu = clf.score(X_test, y_test)\n",
    "\n",
    "print(\"\\033[1mTasa de acierto:\\033[0m %.4f\" %acu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMatriz de confusión:\u001b[0m\n",
      "\n",
      "     A    B    C    D    E    F    G    H    I    W    X    Y  \n",
      "\n",
      "[[2813    0    0    0   12   29    0    1    0    0    2    0]\n",
      " [   3    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  62    0    0    0    0    7    0    0    0    0    0    0]\n",
      " [ 230    0    0    0    1    4    0    0    0    0    0    0]\n",
      " [ 711    0    0    0    1   17    0    0    0    0    1    0]\n",
      " [1284    0    0    0    7   10    0    3    4    0    0    0]\n",
      " [ 295    0    0    0    0    0    0    1    0    0    2    0]\n",
      " [ 299    0    0    0    0   43    0    0    4    0    0    0]\n",
      " [  56    0    0    0    3    2    0    1  489    0    3    0]\n",
      " [  30    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 225    0    0    0    5    1    0    0    0    0  117    0]\n",
      " [ 125    0    0    0    2    0    0    0   19    0   32    0]]\n"
     ]
    }
   ],
   "source": [
    "# Predicciones del conjunto de test\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test,pred)\n",
    "\n",
    "print(\"\\033[1mMatriz de confusión:\\033[0m\\n\")\n",
    "for i in np.unique(y_test):\n",
    "    if (i == 'A'):\n",
    "        print(\"  \",end=\" \")\n",
    "    print(\" \",i,\"\",end=\" \")\n",
    "print(\"\\n\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística con método de validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTasa de acierto:\u001b[0m 0.4992\n"
     ]
    }
   ],
   "source": [
    "# Creación del clasificador de Regresión logística\n",
    "clf = LogisticRegression(random_state=0, multi_class='auto', solver='lbfgs', max_iter=500)\n",
    "\n",
    "# El método cross_val_score utiliza la estrategia de estratificación al ser cv un número entero\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "\n",
    "# Tasa de acierto\n",
    "print(\"\\033[1mTasa de acierto:\\033[0m %.4f\" %np.mean(scores, dtype=np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al realizar el método de Regresión Logística con el dataset Avila, obtenemos resultados mejores que con RLM y vemos que aproximadamente alcanzamos el 50% de aciertos en las predicciones del modelo, aunque esto sigue siendo bastante malo.<br>\n",
    "Seguimos viendo en la matriz de confusión que hay un alto número de predicciones de la clase A cuando esto no es así pero por otro lado las diferencias de la clase I con las demás clases parecen haberse solucionado ya que en la columna de la clase I ya no hay tantas predicciones mal hechas para las demás clases.<br>\n",
    "Como era de esperar al realizar validación cruzada mejoran algo los resultados pero no podemos decir que estos modelos de regresión lineal construidos con los atributos del conjunto de datos sean buenos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
